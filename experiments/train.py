import argparse
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from pathlib import Path
from tqdm import tqdm

# --- 1. Correct Imports based on your file tree ---
from ml_core.data.tcga_loader import get_tcga_dataloaders
from ml_core.models.mlp import MLP

def load_config(path):
    with open(path, 'r') as f:
        return yaml.safe_load(f)

def main(args):
    # 2. Setup Device & Config
    config = load_config(args.config)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Running on device: {device}")

    # 3. Data Loading (Uses tcga_loader.py)
    # This reads the splits generated by split_tcga_patients.py
    print("Loading TCGA Data...")
    train_loader, val_loader, test_loader = get_tcga_dataloaders(config)

    # 4. Model Initialization (Uses mlp.py)
    # TRICK: We pass [768, 1, 1] so the MLP calculates 768 input features
    print("Initializing MLP...")
    model = MLP(
        input_shape=[768, 1, 1], 
        hidden_units=config["model"]["hidden_units"],
        num_classes=config["model"]["num_classes"], # 32 classes
        dropout_rate=config["model"]["dropout_rate"]
    )
    model.to(device)

    # 5. Optimizer & Loss
    optimizer = optim.Adam(model.parameters(), lr=config["training"]["learning_rate"])
    criterion = nn.CrossEntropyLoss()

    # 6. Training Loop
    epochs = config["training"]["epochs"]
    save_dir = Path(config["training"]["save_dir"])
    save_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"Starting training for {epochs} epochs...")

    for epoch in range(epochs):
        # --- TRAIN ---
        model.train()
        train_loss = 0
        correct = 0
        total = 0
        
        for x, y, _ in tqdm(train_loader, desc=f"Epoch {epoch+1} [Train]"):
            x, y = x.to(device), y.to(device)
            
            optimizer.zero_grad()
            output = model(x) # MLP flattens [Batch, 768] automatically
            loss = criterion(output, y)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(output, 1)
            total += y.size(0)
            correct += (predicted == y).sum().item()
            
        train_acc = 100 * correct / total
        avg_train_loss = train_loss / len(train_loader)

        # --- VALIDATION ---
        model.eval()
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for x, y, _ in val_loader:
                x, y = x.to(device), y.to(device)
                output = model(x)
                _, predicted = torch.max(output, 1)
                val_total += y.size(0)
                val_correct += (predicted == y).sum().item()
        
        val_acc = 100 * val_correct / val_total

        print(f"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Train Acc={train_acc:.2f}% | Val Acc={val_acc:.2f}%")

    # 7. Save Model
    save_path = save_dir / "tcga_mlp.pth"
    torch.save(model.state_dict(), save_path)
    print(f"Model saved to {save_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, required=True)
    args = parser.parse_args()
    main(args)